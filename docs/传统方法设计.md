# 传统 Baseline 设计文档（对齐当前架构）v2.0

**最后更新：2026-01-11**
**Baseline 名称：Traditional-Structured Extraction + Two-Stage Clustering（No LLM）**

## 1. 设计目标与约束

### 1.1 目标

在不使用任何 LLM 的前提下，产出与主线系统尽量一致的核心产物：

* `aspect_sentiment_valid` 等价的事实表（传统抽取版）
* 与主线一致的 **两阶段聚类**产物：`issue_clusters`、`cluster_stats`
* 与主线一致的评估产物：`evaluation_metrics`
* 可生成报告（传统模板化洞察）用于对比

### 1.2 强约束（与当前实现对齐）

1. **保留现有分层架构**：Application / Agent / Tool / Model / Storage / Data 全部结构不变。
2. **保留 Orchestrator 单写者 + Pipeline Builder + BaseAgent 接口**：传统 baseline 以新增/替换 Agent 的方式接入。
3. **保留版本字段**：所有新增表与输出必须包含 `run_id / pipeline_version / data_slice_id / created_at`，并遵循 append-only。
4. **保留两阶段聚类实现**：复用你现有 `IssueClusterAgent` 与 `ClusteringTool / EmbeddingTool / RerankerTool（可选）`，避免因为聚类差异导致不可比。
5. **唯一替换点**：把

   * `AspectSentimentExtractorAgent`（LLM 抽取）
   * `ClusterInsightAgent`（LLM 洞察）
     替换为对应的 **Traditional Extractor / Traditional Insight**。其余流程尽量复用。

---

## 2. Baseline Pipeline 定义（对齐 Pipeline Builder）

### 2.1 Pipeline Steps（建议）

传统 baseline 建议新建一个 pipeline 定义：`pipeline_traditional_v1`，步骤拓扑与主线保持一致，只替换抽取/洞察两个步骤。

**步骤顺序：**

1. `DataSelectorAgent` → `selected_reviews`
2. `MetaContextAgent` → `meta_context`
3. `PreprocessAgent` → `normalized_reviews`
4. `SentenceBuilderAgent` → `review_sentences`
5. `OpinionCandidateFilterAgent` → `opinion_candidates`（可复用现有规则过滤）
6. **TraditionalAspectSentimentExtractorAgent（新增）** → `aspect_sentiment_raw_traditional`
7. **TraditionalExtractionJudgeAgent（新增/或复用 ExtractionJudge 的部分逻辑）** → `aspect_sentiment_valid_traditional` + `extraction_issues_traditional`
8. `IssueClusterAgent`（复用） → `issue_clusters_traditional` + `cluster_stats_traditional`
9. **TraditionalClusterInsightAgent（新增）** → `cluster_reports_traditional`
10. `EvaluationAgent`（复用） → `evaluation_metrics_traditional`
11. `ReportAssemblerAgent`（复用/轻改） → `final_report_traditional.md`

> 说明：为减少侵入式修改，建议所有传统输出都用 `_traditional` 后缀表名（或同表加 `method` 字段）。如果你当前 TableManager 强约束“11 张中间表”，那就用 **同表结构 + method 字段**，通过 `run_id + method` 分离；如果允许扩表，建议独立表更清晰。

---

## 3. 组件设计（对齐 BaseAgent / Tool Layer）

### 3.1 TraditionalAspectSentimentExtractorAgent（新增，替代 LLM 抽取）

#### 3.1.1 职责

从 `opinion_candidates` 里 `is_candidate=true` 的句子中，基于**传统 NLP + 规则/词典/统计特征**抽取：

* `aspect`（方面/部件/维度）
* `sentiment`（情感极性 + 分数）
* `issue`（可聚类的问题短语）
* `evidence`（必须可在 `target_sentence` 定位的片段）

#### 3.1.2 输入（从 DuckDB 读）

* `review_sentences`：`sentence_id, target_sentence, context_text, parent_asin, timestamp, rating, helpful_vote ...`
* `opinion_candidates`：`sentence_id, is_candidate, filter_reason ...`
* 可选：`meta_context`：`product_title, features_short, main_category ...`（用于过滤跑题 aspect）

#### 3.1.3 核心处理流程（软件设计层描述）

> 注意：这里描述“做什么”，不涉及代码实现细节。

**阶段 A：候选 Aspect 生成（Candidate Generation）**

* 目标：得到若干 `aspect_raw` 候选，保证召回率。
* 方法族（可组合）：

  1. 名词短语候选：从句子中提取名词/名词短语作为候选
  2. 领域词表补充：用一个可配置的 `ASPECT_SEED_LEXICON`（如 battery/screen/size/quality 等）命中时加入
  3. 上下文回指补偿：当 `target_sentence` 多为代词（it/this）时，允许从 `context_text` 的前一句抽取名词短语作为弱候选（但 evidence 仍必须在 target_sentence 中）

**阶段 B：Aspect 过滤与排序（Filtering & Ranking）**

* 去噪规则：过滤泛化词（product/item/thing/it 等）、停用名词（review/amazon 等）
* 元数据约束（可选）：如果候选在 `meta_context`（title/features）有出现或语义相近，则提升优先级；完全不相关则降权
* 排序信号：与情感线索（情感词/否定词/程度词）距离更近者优先；句法/位置特征可做加权

**阶段 C：Sentiment 判别（Sentence/Aspect Sentiment）**

* 输出：`sentiment ∈ {positive, negative, neutral}` + `sentiment_score`
* 可配置两种策略（作为 baseline 内部消融）：

  * `LEXICON_RULE`：情感词典计分 + 否定反转 + 程度加权（强可解释、稳定）
  * `WEAK_SUPERVISED`：用 rating 弱监督训练的传统分类器（更贴域，但需要训练步骤与模型版本管理）
* 决策：

  * 句子级 sentiment 默认应用到句子内所有 aspect；
  * 若支持 aspect 级别的情感窗口（围绕 aspect 的局部窗口），可为每个 aspect 单独算分。

**阶段 D：Issue 短语抽取（Issue Phrase Extraction）**

* 目标：生成便于聚类的 `issue_raw`，且尽量短、具体、稳定。
* 规则族：

  1. 窗口抽取：在 aspect 左右窗口内抽取动词/形容词短语（如 “drains fast / too small / stopped working”）
  2. 模板抽取：`aspect + is/are + adj`、`aspect + verb + obj`、`too + adj`、`not + adj` 等
  3. 失败回退：如果无法抽到结构化短语，退化为“情感词 + 最近谓词/形容词”组合
* 规范化：小写、词形归一、停用词清理、同义表替换（可选）

**阶段 E：Evidence 定位（Traceability First）**

* 输出的 `evidence` 必须是 `target_sentence` 的可定位子串或 token span
* 若 issue 来自 context 的推断但无法在 target 定位，必须降级 `validity_label=INVALID` 并记录原因

#### 3.1.4 输出（返回给 Orchestrator 写入）

表：`aspect_sentiment_raw_traditional`（一条句子可能多条 aspect 记录）
建议字段：

* 版本字段：`run_id, pipeline_version, data_slice_id, created_at`
* 业务字段：

  * `sentence_id`
  * `aspect_raw`
  * `issue_raw`
  * `sentiment`、`sentiment_score`
  * `evidence`（可定位）
  * `extract_method`（LEXICON_RULE / WEAK_SUPERVISED / HYBRID）
  * `debug_features`（可选：命中的规则/模板/关键词，便于审计）

---

### 3.2 TraditionalExtractionJudgeAgent（新增，替代/复用 ExtractionJudge）

#### 3.2.1 职责

对传统抽取结果做“统一质量门禁”，使其能无缝进入你现有的 `IssueClusterAgent` 两阶段聚类：

* aspect 同义归一（taxonomy）
* issue 归一（轻量同义/词形）
* 噪声/无效记录过滤（NOISE/INVALID）
* rating 弱一致性冲突标记（quality_flags）

#### 3.2.2 输入

* `aspect_sentiment_raw_traditional`
* `review_sentences`（用于 evidence 复核）
* 可选：`meta_context`

#### 3.2.3 校验规则（必须与主线一致）

* `aspect_raw/issue_raw` 泛化词或过短 → `NOISE`
* `evidence` 不可在 `target_sentence` 定位 → `INVALID`
* `sentiment` 与 rating 强冲突 → `quality_flags += RATING_CONFLICT`
* aspect taxonomy：

  * 输出 `aspect_norm`（标准名），并记录 `aspect_norm_source`（taxonomy/manual/map）

#### 3.2.4 输出

1. `aspect_sentiment_valid_traditional`（对齐你主线 `aspect_sentiment_valid` 的结构）
   字段建议：

* 版本字段：`run_id, pipeline_version, data_slice_id, created_at`
* 主字段：`sentence_id, parent_asin, timestamp, rating`
* 抽取字段：`aspect_norm, sentiment, sentiment_score, issue_norm, evidence`
* 门禁字段：`validity_label (VALID/NOISE/INVALID), quality_flags`

2. `extraction_issues_traditional`
   用于记录失败与原因（便于调参、分析传统方法不足）：

* `sentence_id`
* `error_type`（EVIDENCE_NOT_FOUND / GENERIC_ASPECT / EMPTY_ISSUE ...）
* `details`（可选）

---

### 3.3 IssueClusterAgent（复用，保持两阶段聚类一致性）

#### 3.3.1 输入

* `aspect_sentiment_valid_traditional` 中 `validity_label=VALID`

#### 3.3.2 关键对齐点（必须一致）

* **结构化输入文本**：沿用你现有 `IssueClusterAgent` 的格式
  `cluster_text = "Aspect: {aspect_norm}\nIssue: {issue_norm}"`
* **两路向量**：仍生成 `E_aspect` 与 `E_issue`（embedding 模型相同、batch 配置相同）
* **阶段C1 aspect 合并**：Agglomerative 合并同义 aspect（保持阈值与配置口一致）
* **阶段C2 桶内聚类**：<1000 用 Agglomerative，>=1000 用 HDBSCAN（沿用）
* **Reranker 精修**：同样作为可选开关（避免传统 baseline 因为“少了 reranker”导致不公平）

#### 3.3.3 输出

* `issue_clusters_traditional`
* `cluster_stats_traditional`

> 如果你选择“同表 + method 字段”方案，那么输出写入 `issue_clusters/cluster_stats`，但带 `method='traditional'`。

---

### 3.4 TraditionalClusterInsightAgent（新增，替代 LLM 洞察）

#### 3.4.1 职责

不使用 LLM，对每个簇生成可读的洞察条目（簇名、摘要、证据、建议、优先级），并保持字段结构与主线 `cluster_reports` 尽量一致，方便 UI/报告复用。

#### 3.4.2 输入

* `cluster_stats_traditional`（含规模、负面率、代表样本 sentence_id）
* `review_sentences`（取证据文本）
* 可选：`meta_context`（用来生成更贴合商品的建议模板）

#### 3.4.3 洞察生成策略（模板化、可解释）

* `cluster_name`：

  * 选簇内 top issue 词组 / medoid 对应 issue_norm 的短标题
  * 格式建议：`{aspect_norm}: {top_issue_phrase}`
* `summary`：

  * 模板：

    * “用户在 {aspect_norm} 方面主要反馈 {top_terms}，负面率 {neg_ratio}，样本量 {count}；近期趋势 {trend}。”
* `evidence_items`：

  * 直接从 `representative_sentence_ids` 取 3~5 条 `target_sentence`（保证可回溯）
* `action_items`：

  * 规则映射：关键词→建议模板（可配置表 `issue_to_action_rules`）
  * 若无规则命中，给通用建议：例如“检查一致性/加强质检/完善说明书/优化包装”等
* `priority`：

  * 规则：`count × neg_ratio × trend_weight` 分桶为 high/medium/low，并输出 rationale（可选）

#### 3.4.4 输出

表：`cluster_reports_traditional`
字段建议（尽量贴你现有 schema）：

* `cluster_name`
* `summary`
* `priority`
* `priority_rationale`（可选）
* `evidence_items`（结构化：sentence_id + quote）
* `action_items`（结构化：title + detail）
* `confidence`（可选：基于簇内一致性/分离度生成一个规则分数）

---

## 4. 表设计与 TableManager 适配

你当前 TableManager 有“11 张中间表”的核心集合。传统 baseline 有两种接入方式：

### 4.1 方案 A：新增传统专用表（推荐：最清晰）

新增表（与主线一一对应）：

* `aspect_sentiment_raw_traditional`
* `aspect_sentiment_valid_traditional`
* `extraction_issues_traditional`
* `issue_clusters_traditional`
* `cluster_stats_traditional`
* `cluster_reports_traditional`
* `evaluation_metrics_traditional`（可选，也可以复用同表加 method）

优点：不污染主线表结构；对比查询简单。
代价：TableManager 增表 + create_all_tables 增加创建逻辑。

### 4.2 方案 B：复用主线表 + method 字段（兼容“必须 11 表”限制）

在以下表中增加字段 `method`（或你已有的同类字段），并在写入时固定：

* `aspect_sentiment_raw`：method=traditional
* `aspect_sentiment_valid`：method=traditional
* `extraction_issues`：method=traditional
* `issue_clusters/cluster_stats/cluster_reports/evaluation_metrics`：method=traditional

优点：不增加表数量，最小改动。
风险：查询必须始终带 `run_id + method`，否则容易混淆。

> 无论哪种方案：必须保持 append-only，并在 Orchestrator 写入时填充版本字段。

---

## 5. 与现有 Tool Layer 的关系（尽量复用）

### 5.1 必复用

* `ClusteringTool`（算法选择逻辑保持一致）
* `EmbeddingTool`（传统 baseline 仍然使用 embedding 做聚类，避免“聚类能力差异”影响对比）
* `LoggingTool`（统一日志、失败率、统计口径）

### 5.2 可复用（视你实现情况）

* `RerankerTool`（可选开关，为公平对比建议同样开启/同样关闭）
* `StructuredOutputTool`：传统 baseline 不需要解析 LLM，但可以复用其“结构化校验”思想：例如对 `evidence_items/action_items` 的 schema 校验（如果你愿意保持同样的 Pydantic 输出结构）

---

## 6. Evaluation 对齐（同口径对比）

传统 baseline 的 `EvaluationAgent` 不需要改逻辑，只需让它能读到传统输出表/同表 method=traditional 的记录。

### 6.1 自动指标（保持一致）

* `candidate_coverage`
* `extraction_success`（传统里可以定义为：成功产出 raw 记录且通过 judge 的比例）
* `valid_rate`
* `silhouette`
* `noise_ratio`

### 6.2 人工抽样包（保持一致）

抽样的 `sentence_id` 固定，然后并排展示：

* LLM 抽取结果 vs Traditional 抽取结果
  确保人工评估可直接横向打分。

---

## 7. 断点续跑与版本一致性（对齐 Orchestrator）

### 7.1 断点续跑

* `TraditionalAspectSentimentExtractorAgent` 与 `TraditionalClusterInsightAgent` 也必须遵循：

  * 读取时按 `run_id` 过滤
  * 写入 append-only
  * 若表里已存在当前 run_id 的输出，则根据 `resume_from` 跳过

### 7.2 版本字段与配置落盘

* 在 `outputs/runs/<run_id>/config/` 中记录：

  * traditional baseline 的规则版本：`lexicon_version / taxonomy_version / issue_pattern_version`
  * sentiment 方法：LEXICON_RULE 或 WEAK_SUPERVISED（及其模型版本）
  * 聚类配置保持与主线一致（避免混淆因子）

---

## 8. 传统 Baseline 的“可配置项”规范（映射到 configs/runs/*.yaml）

建议新增配置块 `traditional:`：

* `traditional.opinion_filter`

  * 句长阈值、情感词表、否定词表、转折词表、过滤策略开关
* `traditional.aspect_extraction`

  * aspect seed lexicon、stop nouns、是否启用 meta_context 约束、最大候选数
* `traditional.sentiment`

  * method: `LEXICON_RULE` | `WEAK_SUPERVISED`
  * 词典路径/版本；或弱监督训练配置（若启用）
* `traditional.issue_extraction`

  * 模板集合开关、窗口大小、规范化规则、同义表
* `traditional.judge`

  * 泛化词表、evidence 校验开关、冲突阈值
* `traditional.insight`

  * 命名策略、证据条数、action rule 表、priority 规则

---

## 9. 你需要在 README.md 增补的内容（仅建议，不代你改文件）

为了符合你“新增/修改需要改 README”的约束，README 建议加一节：

* **Pipelines**

  * `pipeline_llm_v1`（主线）
  * `pipeline_traditional_v1`（传统 baseline）
* **How to run**

  * `--pipeline traditional`（或对应配置）
* **Outputs**

  * 传统 baseline 的表名/或 method 过滤方式
* **Reproducibility**

  * 传统规则版本如何记录、如何对齐 run_id

---

## 10. 对照实验建议（与你当前实现最“公平”的对比）

为保证公平性，建议固定：

1. 同一个 `selected_reviews`（同一个 data_slice_id）
2. 同一个 `review_sentences`（同一句子切分与上下文策略）
3. 同一个 `IssueClusterAgent` 配置（embedding 模型、阈值、HDBSCAN/Agglomerative 参数一致）
4. 只比较“抽取质量差异”与“洞察生成差异”

   * 抽取：LLM vs Traditional
   * 洞察：LLM 生成 vs 模板化生成

