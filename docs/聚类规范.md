下面把我前面提到的思路（结构化输入 + instruction、aspect/issue 分开建模、两阶段聚类、HDBSCAN/图聚类、reranker 二次判别、MRL 维度裁剪、后处理与增量更新）**整合成一条可落地的完整流程**，并把每一步的实现细节写清楚（不写代码）。

我会基于 Qwen3-Embedding 官方/技术报告里明确的机制来描述：

* embedding 侧：输入末尾加 `[EOS]`（`<|endoftext|>`），最终向量取最后一层该 `[EOS]` 的 hidden state；instruction 与 query 会拼到同一上下文里([arXiv][1])
* reranker 侧：用 chat template，把任务做成“yes/no”二分类，通过下一个 token 是 “yes” 还是 “no” 的概率得到相关性分数([arXiv][1])
* 推荐的 instruction 格式为 `Instruct: ...\nQuery: ...`，且训练中多数 instruction 是英文，英文指令更稳([DeepWiki][2])
* 产出的 embedding 通常会做 L2 normalize，并用 cosine 相似度([DeepWiki][3])
* 模型支持 MRL（可裁剪维度）([Qwen][4])

---

## 总体目标先定清楚（决定你后面所有阈值与结构）

你的数据是一条条 `(aspect, issue)`，你要的聚类通常有两种目标，先选一种（也可以两者都产出）：

1. **“同一 aspect 下的 issue 类型聚类”**（最常见、最可解释）

   * 输出像：`物流 → {到货慢, 丢件, 派送态度差, …}`
2. **“跨 aspect 的同类 issue 聚类”**（更偏挖共性/归因）

   * 输出像：`破损 → {包装破损/商品破损/运输破损…}`

下面的流程我按 **(1) 作为主线** 来写，同时在关键节点告诉你怎么兼容 (2)。

---

# 流程概览（离线构建 → 聚类 → 精修 → 产出 → 增量更新）

* **阶段 A：为聚类而设计的文本输入（结构化 + instruction）**
* **阶段 B：embedding 生成与向量设计（issue 主向量 + aspect 辅向量 + 可选 MRL）**
* **阶段 C：两阶段聚类（先 aspect 分桶，再桶内聚 issue）**
* **阶段 D：用 Qwen3-Reranker 做边界精修（可选但很强）**
* **阶段 E：簇后处理（命名、合并、噪声处置、导出）**


下面逐步展开。

---



## 阶段 A：为“聚类”设计输入文本（结构化 + instruction）

这里是你当前方法的最大升级点：**不要把 aspect+issue 直接拼成一句话**，而是用“稳定结构 + 明确任务指令”。

### A1. 统一结构化模板（强烈建议）

为每条记录构造一个“聚类输入文本”（我叫它 `cluster_text`）：

建议模板（中文内容 OK）：

* 第一行：`Aspect: {aspect_normalized}`
* 第二行：`Issue: {issue_normalized}`
* 第三行（可选但推荐）：`Context: {context_snippet}`

### A2. 给 Qwen3-Embedding 一个“聚类专用 instruction”

Qwen3-Embedding 支持 instruction-aware；官方也建议按任务写 instruction，通常能带来收益([Qwen][4])。DeepWiki/README 里也给了典型模板 `Instruct: ...\nQuery: ...`([DeepWiki][2])。

**实现细节：instruction 建议用英文**（更贴近训练分布）([DeepWiki][3])。你可以直接用下面这条（适合电商评论 issue 聚类）：

> Instruct: Represent the underlying customer issue type for clustering. Texts should be close if they describe the same issue type, even with different wording.
> Query: {cluster_text}

你也可以加“同一 aspect 内聚类”的约束（如果你希望强约束）：

> Instruct: Cluster customer issues within the same aspect. Focus on issue type rather than sentiment intensity.
> Query: {cluster_text}

---

## 阶段 B：Embedding 生成与向量设计（issue 主向量 + aspect 辅向量 + 可选 MRL）

### B1. Embedding 的“取向量方式”要一致

技术报告明确：embedding 模型是在输入末尾追加 `[EOS]`，最终向量取最后一层 `[EOS]` 对应的 hidden state([arXiv][1])。
工程上你要确保：

* 输入确实追加了 `<|endoftext|>`（EOS / eod）
* pooling 逻辑是“last token pooling”（取最后有效 token 的表示），并且处理好 padding([DeepWiki][2])
* 向量做 L2 normalize，后续用 cosine 相似度/距离([DeepWiki][3])

### B2. 不要只做一个向量：建议做“两路向量”

把语义角色拆开，会显著稳：

* **Issue 主向量 `E_issue`**：embed(`Instruct+Query`，其中 Query 用上面的结构化 `cluster_text`)
* **Aspect 辅向量 `E_aspect`**：embed(只包含 aspect 的文本，例如 `Aspect: 物流` 或 `物流`)

  * `E_aspect` 主要用于：分桶、纠错、同义 aspect 合并、跨桶对齐

### B3. 组合策略

**推荐默认：两阶段分桶**（阶段 C 会讲），因此组合向量不一定必须。

**向量拼接**

* 构造最终向量 `V = [ w_i * E_issue ; w_a * E_aspect ]`
* 实现细节：

  * `w_i` 通常 > `w_a`（例如 0.8/0.2 或 0.9/0.1），让 issue 主导
  * 拼接后再整体 L2 normalize（避免维度块影响）

### B4. MRL 维度裁剪

Qwen3 embedding 支持 MRL（可用更短维度的向量）([Qwen][4])。落地建议：

* 做一个小规模 ablation：比如输出维度尝试 `full / 768 / 512 / 256`
* 观察三件事：

  1. 聚类簇内一致性是否下降
  2. 簇是否更碎/更糊
  3. 推理耗时、存储、kNN 检索速度提升多少
* 注意：不同 serving/框架对 “dimensions/MRL” 的参数支持可能不一致，社区有人反馈过某些框架会做能力校验或配置缺失导致问题，所以你要在你自己的推理栈上做一次端到端验证([GitHub][5])

---

## 阶段 C：两阶段聚类（强烈推荐的主流程）

电商评论天然是“维度（aspect）→问题类型（issue）”的层次结构，所以最稳的做法：

### C1. 第 1 层：Aspect 分桶（Bucket）
**先合并同义/近义 aspect，再分桶**
适用于：aspect 抽取存在同义、别名、噪声（如 “物流/配送/快递/发货”）很多。

* 用 `E_aspect` 做一个小规模聚类/相似度合并：

  * 以 cosine 相似度阈值（比如 0.85~0.92）把近义 aspect 合并为“标准 aspect”
* 输出一个 `aspect_canonical_id`，后续按它分桶

> 实现细节：标准 aspect 的确定方式
>
> * 选簇内出现频次最高的字符串作为 canonical name
> * 或者维护一个字典映射到你的业务维度体系

### C2. 第 2 层：桶内对 Issue 聚类（核心）

对每个 aspect 桶，用 `E_issue`（或 `V`）做聚类。**算法建议优先：HDBSCAN 或 图聚类**，因为评论问题分布通常长尾、簇大小不均、噪声多。

#### 选项 1：HDBSCAN 和 Agglomerative 自动选择

实现细节（参数怎么设更像“工程可用”）：

* 距离度量：cosine distance（= 1 - cosine similarity）
* `min_cluster_size`（最小簇大小）：

  * 桶内样本数 n 较大时：建议取 `max(10, n * 0.005)` 这一类的量级
  * n 很小时（<200）：可以取 5~15
* `min_samples`（保守程度）：

  * 想更稳、更少误聚：设大一点（3~10）
  * 想更少噪声点、更多召回：设小一点（1~3）
* 噪声点（-1）处理：留到阶段 F 再做“二次归类”

可选增强：先做 UMAP 再 HDBSCAN（很多场景更稳定）

* UMAP 输入：`E_issue`
* UMAP 输出维度：通常 5~20（不要降到 2 直接聚类，容易形变）
* `n_neighbors`：15~50（越大越倾向全局结构）
* 设定随机种子，保证可复现（UMAP 有随机性）

#### 选项 2：kNN 图 + Leiden/Louvain（非常适合语义聚类）

实现细节（这是“工业很常用”的套路）：

1. 在桶内构建 kNN：每条找 top-k 邻居

   * k 常用 15~50
   * 相似度用 cosine
2. 建图：

   * 节点=样本
   * 边=近邻关系
   * 边权=cosine similarity（可做阈值截断，例如 <0.5 不连边）
   * 建议用 mutual-kNN（双方互为近邻才连边）减少误连
3. 在图上做社区发现（Leiden/Louvain）：

   * `resolution` 控制粒度：

     * resolution 大 → 簇更细
     * resolution 小 → 簇更粗
4. 小簇处理：

   * 小于 `min_cluster_size` 的社区可以先标为“候选合并/噪声”

> 这条路线在你后面引入 reranker 时会特别顺：reranker 的分数可以直接当边权（阶段 D）。

---

## 阶段 D：用 Qwen3-Reranker 做边界精修

你可以把 reranker 当成“二次判别器”：只处理 embedding 近邻里的“边界样本”，成本可控，但能显著减少误聚/漏聚。

技术报告明确 reranker 的输入模板是把任务变成 yes/no 二分类，并用 “yes/no 的概率”当相关性分数([arXiv][1])。

### D1. 候选对生成（先用 embedding 缩小搜索空间）

对每条样本 i：

* 从 `E_issue` 的 ANN/kNN 里取 top-k 候选（比如 50 或 100）
* 只对这些 (i, j) 送 reranker 打分（不要全量两两）

### D2. Reranker 的输入组织（落地细节）

把“是否同一 issue 类型”写成明确任务（建议英文），并把两条记录按 Query/Document 放进去。

* Instruction（示例）：

  * “Decide whether Query and Document describe the same customer issue type for clustering. Answer only yes or no.”
* Query：样本 i 的 `cluster_text`
* Document：样本 j 的 `cluster_text`

然后取分数：`score = P(yes)`（或 yes 的 logit 与 no 的对比）([arXiv][1])

### D3. 用 reranker 分数做“图精修聚类”（推荐用法）

* 构建图：节点=样本
* 对每个 i，只保留 reranker 分数最高的 top-m 条边（比如 m=10~30）
* 边权=reranker score
* 设阈值：score < t 的边丢弃（t 通常在 0.6~0.85 之间，需要你用抽样校准）
* 在这个图上跑 Leiden/Louvain 得到最终簇

> 你会发现：embedding 做“召回”，reranker 做“判别”，组合非常强。

### D4. 簇间合并（跨桶/跨簇对齐的入口）

如果你还想做“跨 aspect 的同类 issue 合并”（目标类型 2）：

* 先得到每个簇的代表文本（阶段 F 会讲怎么选）
* 对簇-簇之间做：embedding 先近邻召回 → reranker 再确认 → 合并

---

## 阶段 E：簇后处理（让结果可用、可解释、可运营）

### E1. 代表样本（Medoid）与簇命名

每个簇选一个代表样本（比“中心点最近”更稳）：

* 计算簇内每条样本到其他样本的平均相似度
* 取平均相似度最高的那条作为 **medoid**

簇命名建议：

* 标准格式：`{aspect_canonical} / {issue_label}`
* `issue_label` 的生成：

  * 规则：抽取 issue 关键词（Top TF-IDF 或高频 n-gram）
  * 或用 LLM/模板总结（但要注意一致性）

### E2. 噪声点与小簇处理

HDBSCAN 或图聚类都会产生噪声/小簇：

* 对噪声点：

  1. 先用 embedding 找最近的簇 medoid/top-k 簇
  2. 若相似度超过阈值（并可选 reranker=“yes”），就“吸附”进该簇
  3. 否则留在 “Other/待归类”
* 对小簇：

  * 若簇内样本高度一致（簇内平均相似度很高）→ 保留（这是长尾问题）
  * 若簇内一致性也不高 → 多半是噪声碎片，优先合并或降级为噪声

### E3. 簇合并与去重（防止“同一问题被分裂成多个簇”）

做簇-簇相似度：

* 用簇 medoid 向量或簇 centroid 向量
* 先用 embedding 找近邻簇，再用 reranker 对 medoid 文本对确认（可选）
* 满足阈值就合并

---

[1]: https://arxiv.org/html/2506.05176v3 "Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models"
[2]: https://deepwiki.com/QwenLM/Qwen3-Embedding/2.3-model-usage-and-api-examples "Model Usage and API Examples | QwenLM/Qwen3-Embedding | DeepWiki"
[3]: https://deepwiki.com/QwenLM/Qwen3-Embedding/2.1-text-embedding-models "Text Embedding Models | QwenLM/Qwen3-Embedding | DeepWiki"
[4]: https://qwenlm.github.io/blog/qwen3-embedding/ "Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models | Qwen"
[5]: https://github.com/QwenLM/Qwen3-Embedding/issues/85?utm_source=chatgpt.com "Embedding Dimension: is_matryoshka parameter is missing ..."
